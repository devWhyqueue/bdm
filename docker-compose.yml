# Common dependencies for Airflow containers
x-airflow-common-depends-on: &airflow-common-depends-on
  redis:
    condition: service_healthy
  postgres:
    condition: service_healthy
  minio:
    condition: service_healthy

# Common dependencies for the "init" services
x-airflow-init-depends-on: &airflow-init-depends-on
  postgres:
    condition: service_healthy
  minio:
    condition: service_healthy
  kafka:
    condition: service_healthy

services:

  # ----------------------------------------------------------------------
  # Database services
  # ----------------------------------------------------------------------
  postgres:
    extends:
      file: ./architecture/database.yml
      service: postgres
    ports:
      - "5432:5432"
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data
      - ./architecture/init-analytics-db.sh:/docker-entrypoint-initdb.d/init-analytics-db.sh

  redis:
    extends:
      file: ./architecture/database.yml
      service: redis

  mongodb:
    extends:
      file: ./architecture/database.yml
      service: mongodb
    ports:
      - "27017:27017"
    volumes:
      - mongo-data:/data/db

  # ----------------------------------------------------------------------
  # Airflow services
  # ----------------------------------------------------------------------
  airflow-webserver:
    extends:
      file: architecture/airflow.yml
      service: airflow-webserver
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init-db:
        condition: service_completed_successfully
      airflow-init-packages:
        condition: service_completed_successfully

  airflow-scheduler:
    extends:
      file: architecture/airflow.yml
      service: airflow-scheduler
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init-db:
        condition: service_completed_successfully
      airflow-init-packages:
        condition: service_completed_successfully

  airflow-init-db:
    extends:
      file: architecture/airflow.yml
      service: airflow-init-db
    depends_on:
      <<: *airflow-init-depends-on

  airflow-init-packages:
    extends:
      file: architecture/airflow.yml
      service: airflow-init-packages
    depends_on:
      <<: *airflow-init-depends-on

  airflow-worker:
    extends:
      file: architecture/airflow.yml
      service: airflow-worker
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init-db:
        condition: service_completed_successfully
      airflow-init-packages:
        condition: service_completed_successfully

  # ----------------------------------------------------------------------
  # Airflow task build services
  # ----------------------------------------------------------------------

  finazon_stream_btc_usdt:
    image: finazon_stream
    build:
      context: ./bdm/ingestion/streaming/finazon
      dockerfile: Dockerfile
    container_name: finazon_stream_btc_usdt
    command: [ "python", "websocket_client.py", "--price-ticks-topic", "btc_usdt_price_ticks", "--stream-topic", "btc_usdt_stream", "--tickers", "BTC/USDT", "--dataset", "crypto" ]
    environment:
      - KAFKA_ENDPOINT=kafka:9092
      - FINAZON_API_KEY=${FINAZON_API_KEY}
    depends_on:
      - kafka

  reddit_bitcoin:
    image: subreddit-scraper
    build:
      context: .
      dockerfile: bdm/ingestion/batch/reddit/Dockerfile
    container_name: reddit_bitcoin_scraper
    command: [ "python", "subreddit_scraper.py", "--help" ]

  finnhub_bitcoin_news:
    image: finnhub-news-scraper
    build:
      context: .
      dockerfile: bdm/ingestion/batch/finnhub/Dockerfile
    container_name: finnhub_bitcoin_news_scraper
    command: [ "python", "news_scraper.py", "--help" ]

  # ----------------------------------------------------------------------
  # Kafka services
  # ----------------------------------------------------------------------
  kafka:
    extends:
      file: ./architecture/kafka.yml
      service: kafka

  kafka-ui:
    extends:
      file: ./architecture/kafka.yml
      service: kafka-ui
    depends_on:
      - kafka

  # ----------------------------------------------------------------------
  # MinIO services
  # ----------------------------------------------------------------------
  minio:
    extends:
      file: ./architecture/minio.yml
      service: minio
    volumes:
      - minio-data:/data

  createbuckets:
    extends:
      file: ./architecture/minio.yml
      service: createbuckets
    depends_on:
      - minio

  # ----------------------------------------------------------------------
  # Flink services
  # ----------------------------------------------------------------------
  jobmanager:
    extends:
      file: ./architecture/flink.yml
      service: jobmanager
    depends_on:
      - kafka
      - minio

  taskmanager:
    extends:
      file: ./architecture/flink.yml
      service: taskmanager
    depends_on:
      - jobmanager
      - kafka
      - minio

  bitcoin-aggregator:
    build:
      context: bdm/processing/streaming/bitcoin_aggregator
      dockerfile: Dockerfile
    container_name: bitcoin-aggregator
    environment:
      - KAFKA_ENDPOINT=kafka:9092
      - KAFKA_TOPIC=btc_usdt
      - MINIO_ENDPOINT=http://minio:9000
      - MINIO_ACCESS_KEY=minioadmin
      - MINIO_SECRET_KEY=minioadmin
      - MINIO_BUCKET=landing-zone
    depends_on:
      - jobmanager
      - taskmanager
      - kafka
      - minio

  iceberg-init-runner:
    image: bitnami/spark:3.5 # Use the same image as spark-iceberg for consistency
    container_name: iceberg-init-runner
    environment:
      # Environment variables for S3A (MinIO) - same as spark-iceberg
      - MINIO_ENDPOINT=http://minio:9000
      - MINIO_ACCESS_KEY=minioadmin
      - MINIO_SECRET_KEY=minioadmin
      - MINIO_BUCKET_TRUSTED_ZONE=trusted-zone
    volumes:
      - ./bdm/processing/iceberg:/opt/bitnami/spark/work/iceberg_scripts # Mount scripts
      - ./architecture/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf # Mount custom Spark defaults
    command: /opt/bitnami/spark/work/iceberg_scripts/run_iceberg_init.sh
    depends_on:
      minio:
        condition: service_healthy
      createbuckets:
        condition: service_completed_successfully
    networks: # Added to ensure it's on the same network
      - bdm_network
    restart: on-failure # Or 'no' if it should only attempt once. 'on-failure' is good for resilience if transient issues occur.

  spark-iceberg:
    image: bitnami/spark:3.5 # Using bitnami image which comes with hadoop S3 support
    container_name: spark-iceberg
    environment:
      - SPARK_MODE=master # Not strictly necessary for spark-sql, but good for a standalone cluster setup
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      # Environment variables for S3A (MinIO)
      - MINIO_ENDPOINT=http://minio:9000
      - MINIO_ACCESS_KEY=minioadmin
      - MINIO_SECRET_KEY=minioadmin
      - MINIO_BUCKET_TRUSTED_ZONE=trusted-zone # For clarity in scripts if needed
    volumes:
      - ./bdm/processing/iceberg:/opt/bitnami/spark/work/iceberg_scripts # Mount scripts
       - ./architecture/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf # Mount custom Spark defaults
    depends_on:
      minio:
        condition: service_healthy
      createbuckets: # Ensure buckets are created before Spark might try to access them
        condition: service_completed_successfully
    networks: # Added to ensure it's on the same network
      - bdm_network
    # command: bin/spark-class org.apache.spark.deploy.master.Master # Example for a master node, not strictly needed for spark-sql if run via exec

  nginx:
    image: nginx:latest
    restart: always
    ports:
      - "80:80"
    volumes:
      - ./architecture/nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - airflow-webserver
      - kafka-ui
      - jobmanager

volumes:
  postgres-db-volume:
  mongo-data:
  minio-data:
  flink-checkpoints:
  flink-usrlib:
